%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall,review,anonymous]{acmart}
%\documentclass[sigconf]{acmart}
%\documentclass[manuscript, screen, review, anonymous]{acmart}

\usepackage{subcaption} 


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{10.1145/XXXXXXX.XXXXXXX}




%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[SIGMOD '25]{2025 International Conference on Management of Data}{June 22--27, 2025}{Berlin, Germany}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/25/06}

\acmSubmissionID{1505}

\begin{document}


\title[Spreadsheet Data Extractor (SDE)]{Spreadsheet Data Extractor (SDE): A Performance-Optimized, User-Centric Tool for Transforming Semi-Structured Excel Spreadsheets into Relational Data}

\author{Alexander Aue-Johr}
%\authornote{Both authors contributed equally to this research.}
\email{alexander.aue@thuenen.de}
\orcid{0009-0001-8683-3630}
\affiliation{%
  \institution{Thünen Institute for Rural Areas}
  \city{Brunswick}
  \country{Germany}
}

\author{Hardy Pundt}
%\authornote{Both authors contributed equally to this research.}
\email{hpundt@hs-harz.de}
\orcid{https://orcid.org/0000-0001-6985-5929 }
\affiliation{%
  \institution{Harz University of Applied Sciences}
  \city{Wernigerode}
  \country{Germany}
}

 

\begin{abstract}
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010405.10010476.10011187.10011189</concept_id>
<concept_desc>Applied computing~Spreadsheets</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002951.10002952.10003219.10003218</concept_id>
<concept_desc>Information systems~Data cleaning</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011050.10010512.10003310</concept_id>
<concept_desc>Software and its engineering~Extensible Markup Language (XML)</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003120.10003121.10003124.10010865</concept_id>
<concept_desc>Human-centered computing~Graphical user interfaces</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003809.10010031.10002975</concept_id>
<concept_desc>Theory of computation~Data compression</concept_desc>
<concept_significance>100</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Applied computing~Spreadsheets}
\ccsdesc[500]{Information systems~Data cleaning}
\ccsdesc[500]{Software and its engineering~Extensible Markup Language (XML)}
\ccsdesc[300]{Human-centered computing~Graphical user interfaces}
\ccsdesc[100]{Theory of computation~Data compression}


\keywords{}
\begin{teaserfigure}
  \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/livestock_hiarachy_1.pdf}
  \caption{}
  \Description{}
  \label{fig:teaser}
\end{teaserfigure}

\received{20 February 2007}
\received[revised]{12 March 2009}
\received[accepted]{5 June 2009}

\maketitle


\section{Introduction}
\cite{R}
A multitude of organizations across various sectors,
including healthcare\cite{berndt2001healthcare},
nonprofit\cite{singh2009numeric}\textsuperscript{,}
\cite{west2008because},
finance, commerce, industry, academia, and government \cite{dunn2010spreadsheets}
frequently encounter difficulties
when attempting to analyse and utilize semi-structured data derived from spreadsheets.
The absence of a defined structure within this data
presents significant challenges for analysis and utilization. 



\begin{figure*}[t]
  \centering

  \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/livestock.pdf}

  \caption[Example data subset of the Agricultural Structure Survey on land use and livestock in Germany]{Example data subset of the Agricultural Structure Survey on land use and livestock in Germany, Source: Own figure}
  
  \label{fig:livestock}
\end{figure*}%

Nevertheless, it is not always the case that there is no structure at all.
There are cases where the data at least has "a" structure.
However, this structure is almost as helpful
as if there were simply none at all.
This is the case for data stored in spreadsheet files like Excel.
The data is not stored in a simple machine-readable wide- or long-format;
rather, it is stored in a format that is designed for human perception,
including layout with empty cells for padding, combined cells,
hierarchies in column headers, multiple tables below one another, and so on.
This is illustrated in Figure \ref{fig:livestock}
These layout techniques facilitate the comprehension of the information
by humans, but they also render the data non-machine readable.
A computer program treats the spreadsheet
as a two-dimensional array of values.
It treats empty cells in the same way
as it treats cells that contain actual data.



 


Compared to unstructured data in raw text, unstructured data in spreadsheets has the following advantages:
The hierarchy of metadata within spreadsheets is easy to comprehend for a human.
Headlines like \textit{Germany} and \textit{Berlin},
referring to our example in Figure \ref{fig:livestock},
combined column headers like \textit{Stock of Calves and Young Cattle}
on top of multiple other column headers like \textit{Quantity} and \textit{LU}
make the metadata hierarchy clear to humans.
The target data structure can be closely inspired by that visible hierarchy
and can be created with a relatively low amount of domain knowledge.
Furthermore, the values are encoded in single cells and can be uniquely
referenced by the file, sheet name and row and column index. 

The objective is to transform this data into a machine-readable form.
When considering the means to achieve this objective,
several approaches present themselves.

The SDE converts semi-structured spreadsheet data into structured formats
by allowing users to define data hierarchies without programming knowledge.

 


The Spreadsheet Data Extractor (SDE) enables users to transform the data from spreadsheets
into structured data by selecting cells containing metadata
and values to describe the data hierarchy.
To streamline the process,
users can copy previously described hierarchies to similar spaces in the sheets,
eliminating the need to select every cell and hierarchy repeatedly.  
Users do not require any programming knowledge to extract the data from the spreadsheet files.
 
 

\begin{table*}[h]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
      \hline
      \textbf{Name} & \textbf{Technologies} & \textbf{Output} & \textbf{Accessibility} & \textbf{Frequency} \\ \hline
      FlashRelate   & AI, GUI               & cleaned data    & proprietary,           & last publication   \\
                    &                       &                 & no access              & 2015               \\ \hline


      Senbazuru     & AI, GUI               & cleaned data    & open source            & last commit        \\
                    &                       &                 &                        & 2015               \\\hline

      XLindy        & AI                    & cleaned data    & no access              & cancelled          \\ \hline
      TableSense    & AI                    & diagrams        & proprietary,           & last commit        \\
                    &                       &                 & no access              & 2021               \\ \hline
  \end{tabular}
  \caption{Spreadsheet Data Extractor counterparts}

  \label{tab:approaches}
\end{table*}


\section{Related Work}

This chapter will first describe
the similar approaches of data extraction
from spreadsheets without programming 
that are found in scientific literature.



\section{Spreadsheet Data Extractor}




Our program's closest research counterparts
are the projects, Senbazuru,  and FlashRelate,
both of which share the goal of extracting relational data from spreadsheets with a graphical user Interface.
\cite{chen2013senbazuru},\cite{barowy2015flashrelate},\cite{koci2019xlindy} 



Senbazuru aims to automatically infer the hierarchical structure
within spreadsheets through the creation of a classifier
that identifies data frames in the document,
along with another classifier that infers the intended hierarchy
using a predefined set of features \cite{chen2013senbazuru}.

While Senbazuru offers automated inference of the hierarchical structure,
it may occasionally produce errors.
In such cases, the tool allows the user to rectify these errors
in the hierarchy by manually dragging and dropping nodes to their correct parent locations.
Unlike Senbazuru, our program does not automatically infer the hierarchical structure.
Instead, our program lets the user decide if the next selection is a child or a sibling of another selection.
To speed up the process,
selections can be duplicated and moved both horizontally and vertically.
Thus, a hierarchy representing a column can be duplicated and shifted over another column,
and similarly,
a hierarchy representing a table can be duplicated and shifted over another table.



FlashRelate utilizes both positive and negative output examples
to generate a program in a domain-specific language called Flare.\cite{barowy2015flashrelate}  
This approach enables FlashRelate
to handle various extraction tasks
from diverse spreadsheets,
as long as it is possible
to identify cells using regular expressions
and recognize the spatial arrangement of the cells.
In contrast to FlashRelate,
our program necessitates the user
to manually choose each data cell containing
either data or metadata.
It does not automatically identify similar cells
based on user-provided selections.
Instead, our program allows users to select not only individual cells
but also sets of cells.
Portions of the spreadsheet
that represent relational data
rather than hierarchical data
can be chosen by first selecting
the domain of the relation as a set of cells.
Typically, the range values of the relation share the same row as the domain values.
In a subsequent step,
the ranges of the relation can be selected
by duplicating the cell set of the domain
and moving it horizontally to the desired cells containing the range values.

There are also two projects that rely on Artificial Intelligence only to identify the hierarchy of the data inside spreadsheets.
Those projects are XLindy and TableSense.
\cite{koci2019xlindy},\cite{dong2019tablesense}

XLindy is not in development any more.
Attempts were made to contact the authors to try the tool and find out if
using it on our test dataset results in reliable output.
Due to the fact that the project is no longer in development
the  tool could not be obtained and tested.

TableSense employs Convolutional Neural Networks
to identify tables in spreadsheets.\cite{dong2019tablesense}  
In their test with the WebSheet400 dataset,
out of 400 random spreadsheets containing 795 tables,
TableSense successfully detected 91.3\% of the tables (recall),
and of the tables detected by TableSense, 86.5\%
were indeed genuine tables (precision).
However, while TableSense excels at detecting table boundaries,
it does not identify data hierarchy or extract data from the tables it identifies.
Our approach currently does not rely on Artificial Intelligence.
Our project's primary focus is to empower users
to manually select all the desired data and describe its hierarchy,
enabling our program to automatically extract this data into a relational format.

\section{Contribution}

Wir bauen auf der bestehenden Arbeit von Alexander Auer, Norbert Röder und Andrea Ackermann auf. Zusätzlich dazu veröffentlichen wir die Software nun unter der Open Source Lizenz GNU Public Licence Version 3 und tragen folgende Verbesserungen bei. Die bestehende Lösung nutzte das Dart-Package excel, um die .xlsx-Dateien zu öffnen. Dies war jedoch sehr langsam, da das Paket die gesamte .xlsx-Datei zunächst vollständig einliest. Wir haben daher eine eigene Funktionalität in Dart implementiert, die die Excel-Arbeitsblätter inkrementell lädt.
Außerdem hat die bestehende Lösung die Zellwerte aus der .xlsx-Datei ausgelesen, dabei jedoch die Breiten und Höhen der Zeilen und Spalten ignoriert und stattdessen deren Größe selbst berechnet, basierend auf dem in den Zellen enthaltenen Text. Dies führte jedoch zu sehr breiten Zellen, die in der ursprünglichen Datei tatsächlich deutlich schmaler waren. Dies lag daran, dass einige Zellen in derselben Spalte sehr langen Text enthielten, um einen Titel darin zu speichern. Durch diese übermäßig breiten Spalten wurde die Navigation durch das Arbeitsblatt erschwert.
Im Vergleich zur ursprünglichen Lösung bietet unsere Version eine Funktionalität, die die Spalten- und Zeilenhöhen und -breiten korrekt ausliest und diese so darstellt, wie es Excel tut. So wird der Benutzer nicht von der Darstellung überrascht.
Die bestehende Lösung hat weiterhin die Zellen gezeichnet, selbst wenn sie nicht im.Aktuellen Viewport sichtbar waren. Das Städte erhebliche Probleme da, wenn Arbeitsblätter mit sehr vielen Zellinhalten geöffnet worden. Die Performance Sankt dabei so stark herab, dass das Programm nicht mehr benutzbar war.Aus diesem Grund haben wir einen Mechanismus implementiert, dass nur zellinhalte gezeichnet werden, die auch tatsächlich sichtbar sind.


\section{Methodology}

\begin{figure*}[h]
  \begin{subfigure}{1.0\textwidth}
    \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/livestock_hiarachy_1.pdf}
    \caption{The data selection view, once all selections are completed}
    \label{fig:livestock_hiarachy_1}
  \end{subfigure}
  \begin{subfigure}{1.0\textwidth}
    \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/livestock_hiarachy_2.pdf}
    \caption{The data selection view, once all selections are completed}
    \label{fig:livestock_hiarachy_2}
  \end{subfigure}
  \caption[Second Level Third Level Questions]{Second Level Third Level Questions, Source: Own figure}
  \label{fig:livestock_hiarachy}  
\end{figure*}

We used the software development kit Flutter
to develop a program with a user interface
that allows the selection of the cells containing the metadata
and data inside the spreadsheet.
We refer again to the example from Figure \ref{fig:livestock}
to describe the necessary steps
required for data extraction from spreadsheets.
We use this example spreadsheet to illustrate
the necessary steps required for data extraction
from spreadsheets like this one.
When looking at the spreadsheet,
a human can identify a hierarchy very easily.
There are sub-tables with headings,
and all the sub-tables share the same columns,
which are only laid out once at the top of the spreadsheet
rather than being repeated for each sub-table.

The headings \textit{Germany} and \textit{Berlin} in this example
are the topmost metadata because most cells containing actual data
share these headings as common metadata,
whereas the metadata of the column header \textit{Agric. Utilised Area}
and \textit{Hectares ha} is only shared by the cells beneath that column.
A human can see these hierarchies,
but to a program, these hierarchies are not visible;
the program just sees a two-dimensional grid of cells,
some empty, some containing text, and some containing numbers.

The computer needs to be able to interpret this hierarchy in the spreadsheet
just as a human does.
However, for that to happen, it needs the hierarchy as input.
Our approach is that the user provides this hierarchy
to the computer by selecting the cells and describing the relationships
they have to one another.

To make this process easier and faster for the user,
the amount of user interaction should be minimized as much as possible.
This can be achieved by selecting the most abstract meta-information first
and then progressively narrowing down to increasingly specific meta-information
until the actual facts are chosen.
Additionally, allowing the user to duplicate selections and hierarchies
to similar areas in the spreadsheet can streamline this process.






\begin{figure*}[!t]
  \centering
  \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/livestock_hiarachy_1.pdf}
  \caption{The data selection view, once all selections are completed}
  \label{fig:livestock_hiarachy_1}
\end{figure*}




 
In Figure \ref{fig:livestock_hiarachy_1}, cells are presented
as they appear within our program's data selection view
after all the selections are made.
Additionally, an additional layer with black arrows illustrates
the optimal sequence of selections for this example,
designed to minimize user interaction.
These arrows, numbered from 1 to 7, represent the specific steps of user interaction.








Please note that the program deconstructs merged cells.
Cells from which the merged cell was created are displayed as individual cells (e.g. \textit{Quantity} and \textit{LU}).
This will be useful for the following selections.


\begin{figure}[h]
    \centering
 
    \includegraphics[width=0.5\textwidth]{images/spreadsheet_data_extractor/duplicate_and_move.png}
 
    \caption[Selecting the tables arranged one below the other]{Selecting the tables arranged one below the other}
    
    \label{fig:duplicate_and_move}
\end{figure}%

The most abstract meta-information, which is the meta-information shared by most cells, is the country or state in this example (Arrow 1). After that, the header of the domain of the relation is selected (Arrow 2) and then the domain itself will be picked (Arrow 3). While Selections 1 and 2 each selected individual cells, Selection 3 introduces the concept of choosing a set of cells.
Moving on to the first data column, the process involves selecting the first column header (Arrow 4), followed by choosing the second column header (Arrow 5). Now, the first range of the relation is selected (Arrow 6).
If the selection of data were to continue in the same manner, this would involve an additional 15 selections just for the first table, offering no significant improvement over manually creating the relation by simply copying and pasting the cells. However, the subsequent selections can be automated,
given that both two column headers and the numeric values are located in the same row, each one cell to the right of the previous one. The program's \textit{Duplicate and Move} function allows these cells to be selected in a single step.
To do this, Selection 4 is chosen, and the duplicate is moved one cell to the right.

A slider can be adjusted to determine the number of duplicates to generate. Each duplicate is moved the same number of cells in the same direction as the previous one.
For this example, the slider is set to create 5 duplicates (see Figure \ref{fig:duplicate_and_move}).
This results in all the selections depicted as arrows labelled 7 in Figure \ref{fig:livestock_hiarachy_1}.

This functionality is made possible by the Spreadsheet Data Extractor's ability
to deconstruct merged cells, such as those in the \textit{Quantity} and \textit{LU} columns.
Without this feature, duplicating and moving selections over these merged columns would fail,
resulting in the cells within the \textit{Quantity} and \textit{LU} columns remaining empty, except for the first cell in each merged group.
However, the Spreadsheet Data Extractor displays the underlying cells of the merged cells as redundant copies.
This approach allows the process of duplicating and moving column selections over these merged areas to work seamlessly.
With this, the first table is captured.



The same procedure used to capture the previous five columns
can be applied to capture the tables arranged below one another.
To do this, Selection 1 is chosen, then duplicated and moved down by six cells.
However, the header cells (B1 to H2) are an exception to this,
because they don't reappear in the tables below.
The program offers a freeze option for this purpose.
The frozen cells are duplicated but remain in their original positions during the move.
Figure \ref{fig:livestock_hiarachy_2} illustrates how the \textit{Duplicate and Move} function was employed
to capture the table below by moving all but the frozen cells down
by six cells (all arrows labelled with the number 8).


After the selections are made,
the hierarchy of selections forms a tree
in which each node contains the selected set of cells.
Except for the first two nodes,
where the first node represents the spreadsheet file (e.g. \textit{Livestock.xlsx})
and the second node represents the workbook's worksheet (e.g. \textit{Calves}). 
This is demonstrated in Figure \ref{fig:tree_horizontal_small}
for the subtree with the root node \textit{Germany}.


\begin{figure*}[ht]
  \begin{subfigure}{1.0\textwidth}
    \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/tree_horizontal_small_v2.pdf}
    \caption[Tree structure of cell sets of subtree Germany]{Tree structure of cell sets of subtree Germany, Source: Own figure}
    \label{fig:tree_horizontal_small}
  \end{subfigure}
  \begin{subfigure}{1.0\textwidth}
    \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/tree_product_horizontal_small_v2.pdf}
    \caption[Cross Product of subtree Germany]{Cross Product of subtree Germany, Source: Own figure}
    \label{fig:tree_product_horizontal_small}
  \end{subfigure}
  \caption[Second Level Third Level Questions]{Second Level Third Level Questions, Source: Own figure}
  \label{fig:livestock_hiarachy}  
\end{figure*}



\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/tree_horizontal_small_v2.pdf}
    \caption[Tree structure of cell sets of subtree Germany]{Tree structure of cell sets of subtree Germany, Source: Own figure}
    \label{fig:tree_horizontal_small}
\end{figure*}%


\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/tree_product_horizontal_small_v2.pdf}
  \caption[Cross Product of subtree Germany]{Cross Product of subtree Germany, Source: Own figure}
  \label{fig:tree_product_horizontal_small}
\end{figure*}%


To transform this tree of sets of cells into relational data,
we calculate the cross product of the tree.
The length of each child set is obtained from the bottom up,
and the parent node is duplicated as many times as necessary
to match the length of that child set (Figure \ref{fig:tree_product_horizontal_small}). 


If the length of the parent and child nodes differ
and the length of the parent set is not a whole number divisor
of the length of the child set,
an error will be thrown,
as it is not possible to duplicate the parent set
to match the length of the child set.
This situation should not occur.
When a parent set consists of more than one cell,
it is usually because the parent set
represents the identifier of the rows,
or in mathematical terms,
the domain of the relation.
This domain must be of the same length as the values represented
to the right of the rows' identifier,
which correspond to the relation range in mathematical terms.
This is also applicable to the table in Figure \ref{fig:livestock},
where the relation's domain comprises
the cells \textit{1-9}, \textit{10-19}, and \textit{20-49},
while the range is located to the right of it.





The final step is to convert each list of sets to tuples
and stack them on top of each other to create the final relation,
as shown in \ref{fig:spreadsheet_data_extractor_output}.
This relation can then be exported as a CSV file.


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{images/spreadsheet_data_extractor/output.pdf}
    \caption[Output relation]{Output relation, Source: Own figure}
    \label{fig:spreadsheet_data_extractor_output}
\end{figure*}%


\subsection{Serialisation}

%\begin{verbatim}
%abstract class TaskList implements Built<TaskList, TaskListBuilder> {
%  BuiltList<ImportExcelFilesTask> get childTasks;
%
%  TaskList._();
%  factory TaskList([void Function(TaskListBuilder) updates]) = _$TaskList;
%
%  static Serializer<TaskList> get serializer => _$taskListSerializer;
%}
%\end{verbatim}

 
 


\subsection{Inkrementelles laden der Excel Dateien. }



Wenn excel Dateien öffnet, dann lädt es zunächst die gesamte Datei mit allen Arbeitsblättern, bevor das erste Arbeitsblatt zur Darstellung gebracht wird.Bei Dateien, die sehr große Arbeitsblätter enthalten, kann dies einige Sekunden bis Minuten dauern.Den Benutzer, das extrahieren aus einer.Anzahl von Excel Dateien zu erleichtern, implementierten Via einen Mechanismus zum Inkrementellen Laden von.Excel Dateien.


Eine exe Datei ist ein zip Archiv, welches einer Reihe an XML Dateien enthält, die die.Workshits die Formatierungen und wiederkehrende Texte beschreiben.Unsere Lösung öffnet zunächst das Archiv, extrahiert aber zunächst keine darin enthaltenen Dateien.Extrahiert unsere Lösung lediglich die Liste der Dateien.Dabei werden alle worksheet Dateien in dem XL worksheets Ordner Zu einem Dictionary hinzugefügt.Dieses Dictionary enthält die Informationen wie den Arbeitsblattnamen.Diese können den Benutzer, wenn er die Oberfläche zum Selektieren von Arbeitsblättern öffnet, direkt als Reiter angezeigt werden. Diese Ansicht, welcher aller Arbeitsblätter als Reiter visualisiert, kann sehr schnell den Benutzer nahezu sofort präsentiert werden, da das Öffnen der Archiv Datei sehr flott vonstatten geht.

Erst wenn der Benutzer auf einen der Reiter der Arbeitsblätter klickt.Parst  unsere Lösung Den Dateiinhalt dieses Arbeitsblattes. Sobald der Dateiinhalt dieses Arbeitsblattes komplett gelesen ist, ersetzen wir in dem Dictionary die. Den Verweis auf die Datei mit dem tatsächlichen Inhalt der Datei. Auf diese Weise wird verhindert, dass die Datei immer wieder beim Aufrufen dieses Arbeitsblattes erneut geparst wird.

Öffnet der Benutzer ein anderes Arbeitsblatt, so wird auch dieses erst beim Zugriff auf das Arbeitsblatt gepasst.Gehensweise ermöglicht es uns jeder.Excel Datei nahezu sofort dem Benutzer zur Anzeige zu bringen und ihm keine Wartezeiten im Öffnen der.Excel Dateien zuzumuten.

\subsection{Darstellung der.Arbeitsblätter}



Damit der Benutzer keine Schwierigkeiten hat, sich im Arbeitsplatz zurechtzufinden, legen wir wert darauf, die Arbeitsblätter so anzuzeigen, wie sie auch in Excel angezeigt werden.

Anzeige der Höhe und Breite

Unsere Lösung extrahiert die Informationen über die Spaltenbreiten und Zeilenhöhen aus dem Arbeitsblatt. Dabei ist darauf zu achten, dass in Excel die Spaltenbreiten und Zeilenhöhen in Excel Einheiten gemessen werden. Diese müssen mit einem Faktor mit impliziert werden, um die tatsächliche Höhe oder Breite in Pixeln zu erhalten.Wichtig dabei zu betrachten ist, dass dieser Faktor unterschiedlich ist. Für die Breite und für die Höhe.Damit die Spaltenbreite genauso bereit erscheint, wie sie in Excel erscheint, muss die angegebene Einheit in der XML Datei mit dem Faktor x multipliziert werden.Um die tatsächliche Zeilenhöher in Pixeln zu erreichen, muss dagegen der Faktor y mit dem Wert der in der exe Datei angegeben wird, multipliziert werden.

\subsection{Overflow}



Genau wie in Excel auch achten wir darauf, dass Text.Bitte die nicht in die Zelle hineinpassen.Durch einen Overflow in die anliegenden Zellen hineinragen.Doch das darf nur geschehen, wenn die anliegenden Zellen nicht selbst Werte enthalten.

Zeichnen wir die Zellen auf diese Art und Weise, erhalten wir eine Darstellung, die Excel sehr nahe kommt.

\subsection{Performance}


Sobald alle Spaltenbreiten und Zeilen Höhen extrahiert wurden, können wir diese Nutzen Um zu berechnen, welche Zellen aktuell sichtbar sind und alle anderen Zellen beim Zeichnen zu ignorieren. Dazu wird das aktuelle Scroll Offset in der x und y Achse berücksichtigt und Dabei wird berechnet.Welche Zellen aktuell sichtbar sind Indem die Spaltenbreiten so lange addiert werden, bis  die Summe die linke Kante des Viewports erreicht. Alle Zellen links davon werden beim Zeichnen ignoriert. Weiterhin werden die Spaltenbreite Breiten weiter addiert, bis sie die rechte Kante des Viewports erreicht.Alles Zellen rechts davon werden beim Zeichnen ignoriert. Weiterhin werden die Zeilenhöhen entweder aus der Standard Höhe.Des Arbeitsblattes oder über die Benutzer definierten Höhen der Zeilen extrahiert und so lange aufaddiert, bis die Summe die obere Kante des Viewports erreicht.Alle Zellen, die oberhalb dieser Kante liegen, werden beim Zeichnen ignoriert.Die Zeilenhöhen werden weiter aufaddiert, bis sie die.Unsere Kante des Viewports erreicht.Nur diese Zellen werden gezeichnet. Alle Zellen unterhalb dieser Kante werden ignoriert.




The amount of unsued cells is likely to be higher,
because our script does not check for cells that seem like they contain contentbecause they reference a shared structuring
but in reality those shared strings are just whitespaces that got into the cells by accident.
Those cells are not filter our by our script because of the performance.
Our script filters out the cells that don't have childdren with a xpath query
which is very fast in comparison to iterating
over every node and checking if the referenced shared string consists of only white spaces.

https://ecma-international.org/publications-and-standards/standards/ecma-376/

Dataset: \cite{vos2024calculations}



\section{Evaluation}


After building the first version of the Spreadsheet Data Extractor,
student assistants successfully used it to extract data from over 500 Excel files.
The time taken for each file was determined from a sample of 331 processed Excel files,
comprising 3,093 worksheets, with outliers caused by pauses removed. On average,
the student assistants required 15 minutes per file and 95 seconds per worksheet. 

Research Question 1 can be answered positively.
Student assistants without programming experience were able to extract data from over 500 Excel files
using the Spreadsheet Data Extractor in a reasonable amount of time.

\section{Outlook}

\section{Fintergrundfarben, Borders}

Um dem Benutzer das Zurechtfinden in den ziArbeitsblättern weiter zu erleichtern, könnte der Spread Sheet Data Extractor weiter erweitert werden, sodass er auch hintergrundfarben, Vordergrundfarben der Texte und Borders.Was von den Zellen genauso anzeigt, wie es auch Exi tut.



The extraction of data from the heterogeneous spreadsheet files was possible,
even though the user experience was not optimal.
Many aspects of the user experience that would have been significant time-saving features
had to be omitted during development due to time restrictions.
These included features for describing the hierarchy of the worksheets and exporting the extracted data.


\subsection{Improvements for Describing the Spreadsheet Hierarchy}

The current version of the Spreadsheet Data Extractor hampers the user experience:
\begin{itemize}
    \item The user needs to switch back and forth between the task view (Figure \ref{fig:spreadsheet_data_extractor_task_view}) and the cell selection view (Figure \ref{fig:spreadsheet_data_extractor_cell_selection_view}).
    \item To duplicate and move a hierarchy, the user must first select each node that should not be moved individually and then freeze them in place.
    \item The user needs to know in advance when to create empty nodes if the number of column headers varies from column to column.
\end{itemize}

\begin{figure}[ht]
  \centering

  \includegraphics[width=0.5\textwidth]{images/spreadsheet_data_extractor/views/task_view.png}

  \caption[The task view listing all nodes in the hiarachy graph]{The task view Listing all nodes in the hiarachy graph, Source: Own figure}
  
  \label{fig:spreadsheet_data_extractor_task_view}
\end{figure}%

\begin{figure}[ht]
  \centering

  \includegraphics[width=0.5\textwidth]{images/spreadsheet_data_extractor/views/cell_selection_view.png}

  \caption[The cell selection view]{The cell selection view, Source: Own figure}
  
  \label{fig:spreadsheet_data_extractor_cell_selection_view}
\end{figure}%

\subsubsection{Switch Between Task View and Cell Selection View}
When creating a new node to describe the task of extracting a cell or set of cells,
the user must switch to the view that displays all tasks.
To export a cell or set of cells, the user must first switch to the view that displays
the cells and then select the desired cell(s) upon node creation.
As the hierarchy of the spreadsheet grows, switching back and forth and finding
the correct nodes becomes increasingly time-consuming.

\subsubsection{Select Each Node Individually to Lock in Place}

The switching of views is increasingly complicated for the user
when duplicating and moving a hierarchy of export tasks.
While in the view showing the cells,
the user might try to duplicate a hierarchy by extracting one sub-table
of a sheet and then move that hierarchy to the next sub-table below.
Only at that point, the user might see that the table below does not repeat the column headers,
and the user might want to freeze those nodes in place.

To freeze the nodes the user needs to switch to the task view once again.
There, they need to look up all nodes that represent the column headers.
The user can only identify those nodes by their extracted value and their cell coordinate,
while it would be much easier to just see the centre in the actual grid.
The column headers are scattered across the whole hierarchy,
which means it will take the user a while to scroll through the hierarchy,
reminding themselves of the extracted values from those column headers
and comparing them with the values shown in the task list.

After the user has used the freeze function,
they can switch back to the view showing the worksheet cells and repeat
the step of duplicating and moving the hierarchy.
Only by that time will the user see if they correctly froze the correct nodes
or if they missed nodes or even selected the wrong ones.

\subsubsection{The User Needs to Know Beforehand When to Create Empty Nodes}



Many tables in our dataset have columns with varying count of headers.
For instance, in Figure \ref{fig:sheeps_columns}
\cite{SB23},
there is one column with the header \textit{Total}
and another with the headers \textit{Ewes}, \textit{Dairy Sheep}, and \textit{Namely}.
The header \textit{Namely} is unnecessary, but \textit{Ewes} is valuable metadata
and should be included in the output relation.
To preserve all metadata, there are two possible solutions.
Columns with multiple headers could be concatenated with a delimiter,
such as \textit{Ewes-Dairy Sheep}.
This would ensure that the number of headers in the column is consistent.
However, this solution has the disadvantage of losing the hierarchy of the headers,
making it impossible to filter the resulting dataset for the metadata \textit{Ewes}.
The second solution would be to add empty nodes for the columns with fewer headers
to match the count of headers in all columns.
In this example, \textit{Total} and \textit{Dairy Sheep} can be treated as metadata of the same level.

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{images/spreadsheet_data_extractor/sheeps_columns.pdf}
    \caption[Varying count of column headers]{Varying count of column headers, Source: Own figure}
    \label{fig:sheeps_columns}
\end{figure*}%

Adding an empty node with the child \textit{Total}
results in the output relation for the rows \textit{Total} and \textit{Dairy Sheep},
as shown in Figure \ref{fig:sheeps_columns_output}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/spreadsheet_data_extractor/sheeps_columns_output.pdf}
    \caption[Output relation with empty nodes]{Output relation with empty nodes, Source: Own figure}
    \label{fig:sheeps_columns_output}
\end{figure}%


To accomplish this, the user must be aware
at the moment they select the \textit{Total} column,
that subsequent columns will have additional column headers.
Therefore, they need to preemptively create an empty node
as the parent of the \textit{Total} node.
If the user forgets to create this parent node
and only realizes the discrepancy in the number of column headers
in subsequent columns, they currently have
to tediously modify the hierarchies of the previous columns.
The user can initially copy the \textit{Total} node,
then delete it, add an empty node in its place,
and finally insert the copied \textit{Total} node as its child.
This process involves a significant number of steps for the user,
resulting in a poor user experience.




 
Improving the user experience of this application could be achieved through several enhancements:

\subsubsection{Integration of Task and Cell Selection Views}

The hierarchy of cell selections could be shown as a side panel, or even better as graphs in the view showing the cells.
In the current version of the Spreadsheet Data Extractor the selected cells are already highlighted.
The hierarchy could be shown by connecting the highlighted sets of cells with arrows pointing to their parent and child nodes.

\subsubsection{Support for Multi-Node Selection}
If the user wishes to freeze cells before duplicating and moving a hierarchy,
the user should be able to select these cells by clicking directly on them.
This could be sped up by allowing the user to select multiple sets of cells
by drawing a line around them,
as is done in other GUIs and is often referred to as the lasso tool.

\subsubsection{Drag-and-Drop Node Manipulation}
Enabling users to drag and drop nodes to rearrange them
within the hierarchy would simplify the process
of organizing and structuring data,
providing a more intuitive way to describe the hierarchy and 
allowing for quick corrections in case of errors.

\subsubsection{Node Wrapping Functionality}

Introducing the feature to wrap user-selected nodes
into new ones would provide users with the flexibility
to create empty nodes on-the-fly as they recognize the need for them.
For example, if a user adds a new column
with more column headers than the existing ones,
they could seamlessly wrap the previous column headers into new nodes
to match the number of headers in each column. 

\subsection{Enhancements for Data Export}


While the extraction of the more than 500 Excel files was a success, it resulted in a few hundred CSV files.
All of these files are in a machine-readable format but are split into many separate files.
A lot of those files have the same amount columns and the  same or a very similar set of metadata columns.
Those files should be combined, because they contain the same type of data, yet different values.
The reason for this is, because the Spreadsheet Data Extractor made it easy for the user to extract data from just one or a few of Excel files.
Using it for a lot of files was impractical, because the task view grew very big with just extracting from one file.
To maintain an overview the student assistants instead created a new configuration when moving to the next Excel file.
That means that the extracted files needed to be combined afterward by comparing them with each other.
When two files are similar, they needed to be merged into a single file


To streamline this process the user experience could be improved by implementing an
input- and output-manager.

\subsubsection{Input Manager}

Firstly, an Input Manager within the Spreadsheet Data Extractor
should facilitate the import of all files,
offering users a comprehensive overview
of all imported files directly within the application.
This feature would discourage users from organizing files externally
and ensure centralized management of file imports.

Additionally, the Input Manager should indicate the extent to which each file's data
has been described through cell selections.
This would aid users in finding out which files need to be processed next 
and prevent the need for manual organization of files into directories called "to-do" and "done".


\subsubsection{Output Manager}

Secondly, the Spreadsheet Data Extractor requires an Output Manager.
Instead of exporting hierarchies directly to CSV files,
users should first define a target format specifying column names, data types, and desired order.
Subsequently, users can progressively link newly described hierarchies to existing output formats.
This facilitates efficient data consolidation.
Once all files are described and linked, data can be exported as a small set of CSV files,
ensuring consistency and ease of use.

\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


\end{document}
\endinput
